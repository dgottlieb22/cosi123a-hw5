{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy\n",
    "import sklearn\n",
    "import pandas\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import the uci Molecular Biology (Promoter Gene Sequences) Data Set\n",
    "data=pd.read_csv('training.data', names=['group', 'seq'], header=None)\n",
    "test_data=pd.read_csv('test.data', names=['seq'], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(df, train=True) :\n",
    "    data = df\n",
    "    if train :\n",
    "        groups = data.loc[:, 'group']\n",
    "\n",
    "    sequences = list(data.loc[:, 'seq'])\n",
    "    dataset = {}\n",
    "\n",
    "    # loop through sequences and split into individual nucleotides\n",
    "    for i, seq in enumerate(sequences):\n",
    "\n",
    "        # split into nucleotides, remove tab characters\n",
    "        ncl = list(seq)\n",
    "        ncl = [x for x in ncl if x != '\\t']\n",
    "\n",
    "        # append class assignment\n",
    "        if train:\n",
    "            ncl.append(groups[i])\n",
    "\n",
    "        # add to dataset\n",
    "        dataset[i] = ncl\n",
    "        \n",
    "    \n",
    "    dframe = pd.DataFrame(dataset)\n",
    "    \n",
    "    df = dframe.transpose()\n",
    "    \n",
    "    if train:\n",
    "        df.rename(columns = {60: 'Class'}, inplace = True) \n",
    "\n",
    "    numerical_df = pd.get_dummies(df)\n",
    "    \n",
    "    #remerge the columns by putting anything with a 1 in Class_2 as a 2 in Class_1\n",
    "    if train:\n",
    "        index = numerical_df.index\n",
    "        condition = numerical_df[numerical_df['Class_2']==1]\n",
    "        indices = condition.index.values.tolist()\n",
    "        numerical_df['Class_1'][indices] = 2\n",
    "\n",
    "    #can drop the columns now\n",
    "    #anything that was a 1 in class_2 is now a 2 in class 1\n",
    "    #and anything that was a 1 in class_1 is still a 1\n",
    "    # and the only zeroes left should be those with 1s in class_0\n",
    "    if train:\n",
    "        numerical_df = numerical_df.drop(columns=['Class_2'])\n",
    "        numerical_df = numerical_df.drop(columns=['Class_0'])\n",
    "\n",
    "        numerical_df.rename(columns = {'Class_1': 'Class'}, inplace = True)\n",
    "    \n",
    "    numerical_df = numerical_df.filter(regex = '(?:A|C|G|T|Class)$' , axis=1)\n",
    "    return numerical_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = process(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = process(test_data, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "#create the training sets\n",
    "X = np.array(df.drop(['Class'], 1))\n",
    "y = np.array(df['Class'])\n",
    "\n",
    "#use the same seed to keep the RNG the same\n",
    "seed = 1\n",
    "\n",
    "#split the data\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/jupyterlab/2.1.5/libexec/lib/python3.8/site-packages/sklearn/model_selection/_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM RBF: 0.958852 (0.012329)\n",
      "Test-- SVM RBF:  0.9684361549497847\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95       177\n",
      "           1       0.96      0.95      0.96       168\n",
      "           2       0.99      0.97      0.98       352\n",
      "\n",
      "    accuracy                           0.97       697\n",
      "   macro avg       0.96      0.97      0.96       697\n",
      "weighted avg       0.97      0.97      0.97       697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "names = [\"SVM RBF\"]\n",
    "\n",
    "scoring = 'accuracy'\n",
    "\n",
    "model = SVC(kernel = 'rbf')\n",
    "\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10, random_state = seed)\n",
    "cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "msg = \"%s: %f (%f)\" % (\"SVM RBF\", cv_results.mean(), cv_results.std())\n",
    "print(msg)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "print('Test-- SVM RBF: ',accuracy_score(y_test, predictions))\n",
    "print()\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 0, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1,\n",
       "       2, 2, 1, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2], dtype=uint8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#now for the actual predictions\n",
    "X = np.array(test_df)\n",
    "\n",
    "predictions = model.predict(X)\n",
    "display(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for some reason it wasn't cooperating so I manually saved it\n",
    "\n",
    "lst = [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1,\n",
    "       1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
    "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
    "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
    "       2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
    "       2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
    "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
    "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
    "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
    "       2, 2, 0, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1,\n",
    "       2, 2, 1, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2,\n",
    "       2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
    "       2, 2, 2, 2, 2, 2, 2]\n",
    "\n",
    "\n",
    "dframe = pd.DataFrame(lst)\n",
    "\n",
    "dframe.to_csv('out.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/jupyterlab/2.1.5/libexec/lib/python3.8/site-packages/sklearn/model_selection/_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K nearest-neighbors: 0.727273 (0.019258)\n",
      "Test--  K nearest-neighbors :  0.7288378766140603\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.92      0.68       177\n",
      "           1       0.77      0.88      0.82       168\n",
      "           2       0.97      0.56      0.71       352\n",
      "\n",
      "    accuracy                           0.73       697\n",
      "   macro avg       0.76      0.79      0.74       697\n",
      "weighted avg       0.81      0.73      0.73       697\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/jupyterlab/2.1.5/libexec/lib/python3.8/site-packages/sklearn/model_selection/_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Classifier: 0.943541 (0.015400)\n",
      "Test--  MLP Classifier :  0.9540889526542324\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94       177\n",
      "           1       0.93      0.93      0.93       168\n",
      "           2       0.98      0.97      0.97       352\n",
      "\n",
      "    accuracy                           0.95       697\n",
      "   macro avg       0.95      0.95      0.95       697\n",
      "weighted avg       0.95      0.95      0.95       697\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/jupyterlab/2.1.5/libexec/lib/python3.8/site-packages/sklearn/model_selection/_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: 0.940191 (0.014709)\n",
      "Test--  Decision Tree :  0.9368723098995696\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       177\n",
      "           1       0.88      0.89      0.88       168\n",
      "           2       0.96      0.95      0.96       352\n",
      "\n",
      "    accuracy                           0.94       697\n",
      "   macro avg       0.93      0.93      0.93       697\n",
      "weighted avg       0.94      0.94      0.94       697\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/jupyterlab/2.1.5/libexec/lib/python3.8/site-packages/sklearn/model_selection/_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: 0.522010 (0.035578)\n",
      "Test--  Random Forest :  0.5236728837876614\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.06      0.11       177\n",
      "           1       1.00      0.02      0.04       168\n",
      "           2       0.52      1.00      0.68       352\n",
      "\n",
      "    accuracy                           0.52       697\n",
      "   macro avg       0.81      0.36      0.27       697\n",
      "weighted avg       0.73      0.52      0.38       697\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/jupyterlab/2.1.5/libexec/lib/python3.8/site-packages/sklearn/model_selection/_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Linear: 0.916268 (0.014234)\n",
      "Test--  SVM Linear :  0.9182209469153515\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.91       177\n",
      "           1       0.88      0.87      0.88       168\n",
      "           2       0.96      0.93      0.94       352\n",
      "\n",
      "    accuracy                           0.92       697\n",
      "   macro avg       0.91      0.91      0.91       697\n",
      "weighted avg       0.92      0.92      0.92       697\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/jupyterlab/2.1.5/libexec/lib/python3.8/site-packages/sklearn/model_selection/_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM RBF: 0.958852 (0.012329)\n",
      "Test--  SVM RBF :  0.9684361549497847\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95       177\n",
      "           1       0.96      0.95      0.96       168\n",
      "           2       0.99      0.97      0.98       352\n",
      "\n",
      "    accuracy                           0.97       697\n",
      "   macro avg       0.96      0.97      0.96       697\n",
      "weighted avg       0.97      0.97      0.97       697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define scoring method\n",
    "scoring = 'accuracy'\n",
    "\n",
    "#put names of models here to be trained\n",
    "names = ['K nearest-neighbors','MLP Classifier','Decision Tree','Random Forest','SVM Linear','SVM RBF']\n",
    "\n",
    "#include their classifiers into this list\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(n_neighbors = 3),\n",
    "    MLPClassifier(alpha = 1),\n",
    "    DecisionTreeClassifier(max_depth = 5),\n",
    "    RandomForestClassifier(max_depth=5,n_estimators=10,max_features=1),\n",
    "    SVC(kernel = 'linear'),\n",
    "    SVC(kernel = 'rbf')\n",
    "]\n",
    "\n",
    "models = zip(names, classifiers)\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state = seed)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    print('Test-- ',name,': ',accuracy_score(y_test, predictions))\n",
    "    print()\n",
    "    print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
